{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# [Introduction to Data Science](http://datascience-intro.github.io/1MS041-2023/)    \n",
    "## 1MS041, 2023 \n",
    "&copy;2023 Raazesh Sainudiin, Benny Avelin. [Attribution 4.0 International     (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. BASH Unix Shell \n",
    "\n",
    "\n",
    "1. Dropping into BASH (Unix Shell) and using basic Shell commands\n",
    "    * `pwd` --- print working directory\n",
    "    * `ls` --- list files in current working directory\n",
    "    * `mkdir` --- make directory\n",
    "    * `cd` --- change directory\n",
    "    * `man ls` --- manual pages for any command\n",
    "    * `head` --- show the first lines of a file\n",
    "2. Grabbing files from the internet using `curl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showURL(url, ht=500):\n",
    "    \"\"\"Return an IFrame of the url to show in notebook with height ht\"\"\"\n",
    "    from IPython.display import IFrame \n",
    "    return IFrame(url, width='95%', height=ht) \n",
    "showURL('https://en.wikipedia.org/wiki/Bash_(Unix_shell)',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dropping into BASH (Unix Shell)\n",
    "\n",
    "Using `%%sh` in a code cell we can access the BASH (Unix Shell) command prompt.\n",
    "\n",
    "Let us `pwd` or print working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# this is a comment in BASH shell as it is preceeded by '#'\n",
    "ls # list the contents of this working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir -p mydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cd mydir\n",
    "pwd\n",
    "ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Use the source\" by `man`-ning the unknown `command`\n",
    "\n",
    "By evaluating the next cell, you are using the `man`ual pages to find more about the command `ls`. You can learn more about any command called `command` by typing `man command` in the BASH shell.\n",
    "\n",
    "The output of the next cell with command `man ls` will look something like the following:\n",
    "\n",
    "```\n",
    "LS(1)                            User Commands                           LS(1)\n",
    "\n",
    "NAME\n",
    "       ls - list directory contents\n",
    "\n",
    "SYNOPSIS\n",
    "       ls [OPTION]... [FILE]...\n",
    "\n",
    "DESCRIPTION\n",
    "       List  information  about  the FILEs (the current directory by default).\n",
    "       Sort entries alphabetically if none of -cftuvSUX nor --sort  is  speci‐\n",
    "       fied.\n",
    "\n",
    "       Mandatory  arguments  to  long  options are mandatory for short options\n",
    "       too.\n",
    "\n",
    "       -a, --all\n",
    "              do not ignore entries starting with .\n",
    "\n",
    "       -A, --almost-all\n",
    "              do not list implied . and ..\n",
    "...\n",
    "...\n",
    "...\n",
    "   Exit status:\n",
    "       0      if OK,\n",
    "\n",
    "       1      if minor problems (e.g., cannot access subdirectory),\n",
    "\n",
    "       2      if serious trouble (e.g., cannot access command-line argument).\n",
    "\n",
    "AUTHOR\n",
    "       Written by Richard M. Stallman and David MacKenzie.\n",
    "\n",
    "REPORTING BUGS\n",
    "       GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
    "       Report ls translation bugs to <http://translationproject.org/team/>\n",
    "\n",
    "COPYRIGHT\n",
    "       Copyright © 2017 Free Software Foundation, Inc.   License  GPLv3+:  GNU\n",
    "       GPL version 3 or later <http://gnu.org/licenses/gpl.html>.\n",
    "       This  is  free  software:  you  are free to change and redistribute it.\n",
    "       There is NO WARRANTY, to the extent permitted by law.\n",
    "\n",
    "SEE ALSO\n",
    "       Full documentation at: <http://www.gnu.org/software/coreutils/ls>\n",
    "       or available locally via: info '(coreutils) ls invocation'\n",
    "\n",
    "GNU coreutils 8.28               January 2018                            LS(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "## uncomment by removing '#' in the next line and try executing this cell\n",
    "# man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grabbing files from internet using curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cd mydir\n",
    "curl -O http://lamastex.org/datasets/public/SOU/sou/20170228.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls mydir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cd mydir/\n",
    "head 20170228.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To have more fun with all SOU addresses\n",
    "Do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir -p mydir # first create a directory called 'mydir'\n",
    "cd mydir # change into this mydir directory\n",
    "rm -f sou.tar.gz # remove any file in mydir called sou.tar.gz\n",
    "curl -O http://lamastex.org/datasets/public/SOU/sou.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pwd\n",
    "ls -lh mydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cd mydir \n",
    "tar zxvf sou.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above two cells, you should have all the SOU (State of Union) addresses. By evaluating the next cell's `ls ...` command you should see the SOU files like the following:\n",
    "\n",
    "```\n",
    "total 11M\n",
    "-rw------- 1 raazesh raazesh 6.6K Feb 18  2016 17900108.txt\n",
    "-rw------- 1 raazesh raazesh 8.3K Feb 18  2016 17901208.txt\n",
    "-rw------- 1 raazesh raazesh  14K Feb 18  2016 17911025.txt\n",
    "...\n",
    "...\n",
    "...\n",
    "-rw------- 1 raazesh raazesh  39K Feb 18  2016 20140128.txt\n",
    "-rw------- 1 raazesh raazesh  38K Feb 18  2016 20150120.txt\n",
    "-rw------- 1 raazesh raazesh  31K Feb 18  2016 20160112.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "ls -lh mydir/sou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "head mydir/sou/17900108.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "head mydir/sou/20160112.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting analysis of the textual content of the *State of the Union (SoU)* addresses by all US presidents was done in:\n",
    "\n",
    "-   [Alix Rule, Jean-Philippe Cointet, and Peter S. Bearman, Lexical shifts, substantive changes, and continuity in State of the Union discourse, 1790–2014, PNAS 2015 112 (35) 10837-10844; doi:10.1073/pnas.1512221112](http://www.pnas.org/content/112/35/10837.full).\n",
    "\n",
    "![](images/F5.large.png)\n",
    "\n",
    "[Image source](http://www.pnas.org/content/112/35/10837/F5.large.jpg)\n",
    "\n",
    "[Fig. 5](http://www.pnas.org/content/112/35/10837.full). A river network captures the flow across history of US political discourse, as perceived by contemporaries. Time moves along the x axis. Clusters on semantic networks of 300 most frequent terms for each of 10 historical periods are displayed as vertical bars. Relations between clusters of adjacent periods are indexed by gray flows, whose density reflects their degree of connection. Streams that connect at any point in history may be considered to be part of the same system, indicated with a single color.\n",
    "\n",
    "**You** *will be able to carry out such analyses and/or critically reflect on the mathematical statistical assumptions made in such analyses, as you learn more during your programme of study after successfully completing this course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How was the `sou.tgz` file created?\n",
    "\n",
    "If you are curious, read: [http://lamastex.org/datasets/public/SOU/README.md](http://lamastex.org/datasets/public/SOU/README.md).\n",
    "\n",
    "Briefly, this is how a website with SOU was scraped by Paul Brouwers and adapted by Raazesh Sainudiin. A data scientist, and more generally a researcher interested in making statistical inference from data that is readily available online in a particular format, is expected to be comfortable with such *web-scraping tasks* (which can be done in more gracious and robust ways using specialised Python libraries). Such tasks also known as *Extract-Load-Transform (ELT)* operations are often time-consuming, expensive and the necessary first step towards extracting value from data.\n",
    "\n",
    "### A bit of bash and lynx to achieve the scraping of the state of the union addresses of the US Presidents,\n",
    "#### by Paul Brouwers\n",
    "\n",
    "The code below is mainly there to show how the text content of each state of the union address was scraped from the following URL:\n",
    "\n",
    "* [http://stateoftheunion.onetwothree.net/texts/index.html](http://stateoftheunion.onetwothree.net/texts/index.html)\n",
    "\n",
    "Such data acquisition tasks is usually the first and cucial step in a data scientist's workflow.\n",
    "\n",
    "We have done this and put the data in the distributed file system for easy loading into our notebooks for further analysis.  This keeps us from having to install unix programs like `lynx`, `sed`, etc. that are needed in the shell script below.\n",
    "\n",
    "\n",
    "```\n",
    "for i in $(lynx --dump http://stateoftheunion.onetwothree.net/texts/index.html | grep texts | grep -v index | sed 's/.*http/http/') ; do lynx --dump $i | tail -n+13 | head -n-14 | sed 's/^\\s\\+//' | sed -e ':a;N;$!ba;s/\\(.\\)\\n/\\1 /g' -e 's/\\n/\\n\\n/' > $(echo $i | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/').txt ; done\n",
    "```\n",
    "\n",
    "Or in a more atomic form:\n",
    "\n",
    "```\n",
    "for i in $(lynx --dump http://stateoftheunion.onetwothree.net/texts/index.html \\\n",
    "\n",
    "        | grep texts \\\n",
    "\n",
    "        | grep -v index \\\n",
    "\n",
    "        | sed 's/.*http/http/')\n",
    "\n",
    "do \n",
    "\n",
    "        lynx --dump $i \\\n",
    "\n",
    "               | tail -n+13 \\\n",
    "\n",
    "               | head -n-14 \\\n",
    "\n",
    "               | sed 's/^\\s\\+//' \\\n",
    "\n",
    "               | sed -e ':a;N;$!ba;s/\\(.\\)\\n/\\1 /g' -e 's/\\n/\\n\\n/' \\\n",
    "\n",
    "               > $(echo $i | sed 's/.*\\([0-9]\\{8\\}\\).*/\\1/').txt\n",
    "\n",
    "done\n",
    "```\n",
    "\n",
    "If you have time and are curious how each of the components in the above pipeline via `|` operators work, try to read `man echo`,  `man sed`,  `man grep`,  `man head`,  `man tail`, and  `man lynx` or `lynx --help`. If a command like `lynx` is not in your system, then you can install it with some work (mostly googling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "## uncomment by removing '#' in the next line and try executing this cell by pressing Ctrl-Enter to see if lynx is installed\n",
    "#lynx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using `lynx` is not that difficult. Suppose you want to dump the contents of [https://lamastex.github.io/research/#available-student-projects](https://lamastex.github.io/research/#available-student-projects) to `stdout` or standard out, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "## uncomment by removing '#' in the next line and try executing this cell if lynx is installed\n",
    "#lynx --dump https://lamastex.github.io/research/#available-student-projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you had fun with BASH! Now let us put BASH to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
