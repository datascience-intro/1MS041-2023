{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# [Introduction to Data Science](http://datascience-intro.github.io/1MS041-2023/)    \n",
    "## 1MS041, 2023 \n",
    "&copy;2023 Raazesh Sainudiin, Benny Avelin. [Attribution 4.0 International     (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains and Random Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Markov chain**, named after [Andrey Markov](https://en.wikipedia.org/wiki/Andrey_Markov), is a mathematical model for a possibly dependent sequence of random variables. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/70/AAMarkov.jpg/330px-AAMarkov.jpg)\n",
    "\n",
    "Intuitively, a Markov Chain is a system which \"jumps\" among several states, with the next state depending (probabilistically) only on the current state. A useful heuristic is that of a frog jumping among several lily-pads, where the frog's memory is short enough that it doesn't remember what lily-pad it was last on, and so its next jump can only be influenced by where it is now.\n",
    "\n",
    "Formally, the Markov property states that the conditional probability distribution for the system at the next step (and in fact at all future steps) given its current state depends only on the current state of the system, and not additionally on the state of the system at previous steps:\n",
    "\n",
    "$$P(X_{n+1} \\ | \\, X_1,X_2,\\dots,X_n) = P(X_{n+1}|X_n). \\,$$\n",
    "Since the system changes randomly, it is generally impossible to predict the exact state of the system in the future. However, the statistical and probailistic properties of the system's future can be predicted. In many applications it is these statistical properties that are important.\n",
    "\n",
    "## Formal definition and terms\n",
    "\n",
    "A Markov chain is a sequence of random variables $X_1, X_2, X_3, \\ldots$ with the Markov property, namely that, given the present state, the future and past states are independent. Formally,\n",
    "\n",
    "$$P(X_{n+1}=x \\ | \\ X_1=x_1, X_2=x_2 \\ldots, X_n=x_n) = P(X_{n+1}=x|X_n=x_n).\\,$$\n",
    "\n",
    "The possible values of $X_i$ or the set of all states of the system form a countable set $\\mathbb{X}$ called the state space of the chain.\n",
    "\n",
    "The changes of state of the system are called transitions, and the probabilities associated with various state-changes are called transition probabilities.\n",
    "\n",
    "Markov chains are often depicted by a weighted directed graph, where the edges are labeled by the probabilities of going from one state to the other states. This is called the flow diagram or transition probability diagram.  The transition probability matrix $\\mathbf{P}$ encodes the probabilities associated with state-changes or \"jumps\" from one state to another in the state-space $\\mathbb{X}$. If $\\mathbb{X}$ is labelled by $\\{0,1,2,\\ldots\\}$ then the $i,j$-th entry in the matrix $\\mathbf{P}$ corresponds to the probability of going from state $i$ to state $j$ in one time-step.\n",
    "\n",
    "$$\\mathbf{P} = \\begin{bmatrix} p_{0,0} & p_{0,1} & p_{0,2} & \\ldots \\\\ p_{1,0} & p_{1,1} & p_{1,2} & \\ldots \\\\ p_{2,0} & p_{2,1} & p_{2,2} & \\ldots \\\\ \\vdots & \\vdots & \\vdots & \\ddots \\end{bmatrix}$$\n",
    "\n",
    "The state of the system at the $n$-th time step is described by a state probability vector $$\\mathbf{p}^{(n)} = \\left( \\mathbf{p}^{(n)}_0, \\mathbf{p}^{(n)}_1, \\mathbf{p}^{(n)}_2,\\ldots \\right)$$ Thus, $\\mathbf{p}^{(n)}_i$ is the probability you will find the Markov chain at state $i \\in \\mathbb{X}$ at time-step $n$ and $\\mathbf{p}^{(0)}_i$ is called the initial probability vector at the convenient initial time $0$.\n",
    "\n",
    " \n",
    "\n",
    "The state space $\\mathbb{X}$ and transition probability matrix $\\mathbf{P}$ completely characterizes a Markov chain.\n",
    "\n",
    "### Example 1: Dry-Wet chain, a toy weather model \n",
    "#### A SageMath break-down of the [Wiki Example](https://en.wikipedia.org/wiki/Examples_of_Markov_chains#A_simple_weather_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import showURL\n",
    "showURL('https://en.wikipedia.org/wiki/Examples_of_Markov_chains#A_simple_weather_model',400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can coarsely describe the weather of a given day by a toy model that states if it is \"wet\" or \"dry\". Each day the weather in our toy model is an element of our state space\n",
    "\n",
    "$$\\mathbb{X} = \\{\\text{\"wet\"}, \\text{\"dry\"}\\}.$$\n",
    "We can make a picture of our toy probability model with a flow diagram or transition probability diagram as follows:\n",
    "\n",
    " \n",
    "\n",
    "<img src=\"images/DryWet.png\" width=400>\n",
    "\n",
    "The probabilities of weather conditions, given the weather on the preceding day, can be represented by a transition probability matrix:\n",
    "\n",
    "$$\\mathbf{P} = \\begin{bmatrix} 0.9 & 0.1\\\\ 0.5 & 0.5 \\end{bmatrix}$$\n",
    "\n",
    "The matrix $\\mathbf{P}$ represents our toy weather model in which a dry day is 90% likely to be followed by another dry day, and a wet or rainy day is 50% likely to be followed by another wet day. The columns can be labelled \"dry\" and \"wet\" respectively, and the rows can be labelled in the same manner. For convenience, we will use integer labels $0$ and $1$ for \"dry\" and \"wet\", respectively.\n",
    "\n",
    "$(\\mathbf{P})_{i j}=p_{i,j}$ is the probability that, if a given day is of type $i$, it will be followed by a day of type $j$.\n",
    "\n",
    "Since the transition probability matrix $\\mathbf{P}$ is a stochastic matrix:\n",
    "\n",
    " \n",
    "\n",
    "The rows of $\\mathbf{P}$ sum to $1$.\n",
    "The probabiltites in each row can be thought of as \"current-state\" specific $de~Moivre(p_{i,j}'s)$ distribution\n",
    "Basically, you toss a current-state-specific many-faced weigted die to determine the next state\n",
    "How can we think of our toy weather model in terms of two Bernouli trials; $Bernoulli(0.9)$ and $Bernoulli(0.5)$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct and assign the matrix to `P`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.9, 0.1],\n",
       "        [0.5, 0.5]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "P = np.matrix([[9/10,1/10],[1/2,1/2]])\n",
    "P               # display P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0,1]   # recall accessing (i,j)-th entry of matrix P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the weather with our Dry-Wet chain\n",
    "\n",
    "The weather on day 0 is known to be dry. This is represented by a probability vector in which the \"dry\" entry is 100%, and the \"wet\" entry is 0%:\n",
    "\n",
    "$$ \\mathbf{p}^{(0)} = \\begin{bmatrix} 1 & 0 \\end{bmatrix} $$\n",
    "The weather on day 1 can be predicted by:\n",
    "\n",
    "$$ \\mathbf{p}^{(1)} = \\mathbf{p}^{(0)} \\ \\mathbf{P} = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.5 & 0.5 \\end{bmatrix} = \\begin{bmatrix} 0.9 & 0.1 \\end{bmatrix} $$\n",
    "\n",
    "Thus, there is an 90% chance that day 1 will also be sunny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = np.matrix((1,0))    # initial probability vector for a dry day zero\n",
    "p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.9, 0.1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = p0*P                  # left multiply the matrix by the state prob vector\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather on day 2 can be predicted in the same way:\n",
    "\n",
    "$$\\mathbf{p}^{(2)} =\\mathbf{p}^{(1)} \\ \\mathbf{P} = \\mathbf{p}^{(0)} \\ \\mathbf{P}^2 = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\ \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.5 & 0.5 \\end{bmatrix}^2 = \\begin{bmatrix} 0.86 & 0.14 \\end{bmatrix}$$\n",
    "or, equivalently,\n",
    "\n",
    "$$ \\mathbf{p}^{(2)} =\\mathbf{p}^{(1)} \\ \\mathbf{P} = \\begin{bmatrix} 0.9 & 0.1 \\end{bmatrix} \\ \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.5 & 0.5 \\end{bmatrix} = \\begin{bmatrix} 0.86 & 0.14 \\end{bmatrix} $$\n",
    "How do we do this in Sage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.86, 0.14]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = p0*P**2       # left multiply the initial probability vector by square of P\n",
    "p2                # disclose the probability vector at time-step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, equivalently,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.86, 0.14]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = p1*P  # left multiply the probability vector at time-step 1 by P\n",
    "\n",
    "# disclose the probability vector at time-step 2 (compare output of previous cell)\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General rules for day $n$ follow from mathematical induction as follows:\n",
    "\n",
    "$$ \\mathbf{p}^{(n)} = \\mathbf{p}^{(n-1)} \\ \\mathbf{P} $$\n",
    "$$ \\mathbf{p}^{(n)} = \\mathbf{p}^{(0)} \\ \\mathbf{P}^n $$\n",
    "How do we operate with a matrix in SageMath to do this for any given $n$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.844, 0.156]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3                     # assign some specific time-step or day\n",
    "dry_p0 = np.matrix((1,0))    # initial probability vector for a dry day zero\n",
    "pn = dry_p0 * P**n         # probability vector for day n\n",
    "pn                        # display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.78, 0.22]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 3                     # assign some specific time-step or day\n",
    "wet_p0 = np.matrix((0,1))    # initial probability vector for a wet day zero\n",
    "pn = wet_p0 * P**n         # probability vector for day n\n",
    "pn                        # display it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the state probability vector at time n = 0,1,...,nmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, matrix([[0., 1.]])),\n",
       " (1, matrix([[0.5, 0.5]])),\n",
       " (2, matrix([[0.7, 0.3]])),\n",
       " (3, matrix([[0.78, 0.22]]))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmax = 3             # maximum number of days or time-steps of interest\n",
    "[(n, np.matrix((0,1)) * P**n ) for n in range(nmax+1)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next interact let's visualize the $n$-step state probability vector $\\mathbf{p}^{(n)}=(\\mathbf{p}^{(n)}_0,\\mathbf{p}^{(n)}_1)$, $n=0,1,\\ldots, {\\tt nmax}$ steps\n",
    "\n",
    "\n",
    "See what's going on here...? \n",
    "\n",
    "Try to increase `nmax` and see where the state prob vector is going geometrically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.matrix((1,0)) * P**n  for n in range(nmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fb44f558074ecdb73147e7c1858bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='nmax', max=50, min=1), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "@interact\n",
    "def nStepProbVec(nmax=IntSlider(1,1,50,1)):\n",
    "    import matplotlib.pyplot as plt\n",
    "    dry_p0 = np.stack([np.matrix((0.2,0.8)) * P**n  for n in range(nmax)],axis=0)\n",
    "    plt.scatter(np.array(dry_p0[:,0]),np.array(dry_p0[:,1]),color='red',alpha=0.5)\n",
    "    \n",
    "    wet_p0 = np.stack([np.matrix((.6,0.4)) * P**n  for n in range(nmax)],axis=0)\n",
    "    plt.scatter(np.array(wet_p0[:,0]),np.array(wet_p0[:,1]),alpha=0.5)\n",
    "    plt.xlabel('dry')\n",
    "    plt.ylabel('wet')\n",
    "    plt.xlim(0,1)\n",
    "    plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady state of the weather in our Dry-Wet chain\n",
    "\n",
    "In this example, predictions for the weather on more distant days are increasingly inaccurate and tend towards a steady state vector. This vector represents the probabilities of dry and wet weather on all days, and is independent of the initial weather.\n",
    "\n",
    "The steady state vector is defined as:\n",
    "\n",
    "$$\\mathbf{s} = \\lim_{n \\to \\infty} \\mathbf{p}^{(n)}$$\n",
    "\n",
    "but only converges to a strictly positive vector if $\\mathbf{P}$ is a regular transition matrix (that is, there is at least one $\\mathbf{P}^n$ with all non-zero entries making the Markov chain irreducible and aperiodic).\n",
    "\n",
    "Since the $\\mathbf{s}$ is independent from initial conditions, it must be unchanged when transformed by $\\mathbf{P}$. This makes it an eigenvector (with eigenvalue $1$), and means it can be derived from $\\mathbf{P}$. For our toy model of weather:\n",
    "\n",
    " \n",
    "\n",
    "$$\\begin{matrix} \\mathbf{P} & = & \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.5 & 0.5 \\end{bmatrix} \\\\ \\mathbf{s} \\ \\mathbf{P} & = & \\mathbf{s} & \\mbox{(} \\mathbf{s} \\mbox{ is unchanged by } \\mathbf{P} \\mbox{.)} \\\\ & = & \\mathbf{s} \\ \\mathbf{I} \\\\ \\mathbf{s} \\ (\\mathbf{P} - \\mathbf{I}) & = & \\mathbf{0} \\\\ & = & \\mathbf{s} \\left( \\begin{bmatrix} 0.9 & 0.1 \\\\ 0.5 & 0.5 \\end{bmatrix} - \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\right) \\\\ & = & \\mathbf{s} \\begin{bmatrix} -0.1 & 0.1 \\\\ 0.5 & -0.5 \\end{bmatrix} \\end{matrix}$$ $$\\begin{bmatrix} \\mathbf{s}_0 & \\mathbf{s}_1 \\end{bmatrix} \\begin{bmatrix} -0.1 & 0.1 \\\\ 0.5 & -0.5 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 \\end{bmatrix}$$\n",
    " \n",
    "\n",
    "\n",
    "So $- 0.1 \\mathbf{s}_0 + 0.5 \\mathbf{s}_1 = 0$ and since they are a probability vector we know that $\\mathbf{s}_0 + \\mathbf{s}_1 = 1$.\n",
    "\n",
    "Solving this pair of simultaneous equations gives the steady state distribution:\n",
    "\n",
    " \n",
    "\n",
    "$$\\left( \\mathbf{s}_0 , \\mathbf{s}_1 \\right) = \\left( 5/6 , 1/6 \\right) = \\left( 0.833 , 0.167 \\right)$$\n",
    " \n",
    "\n",
    "In conclusion, in the long term, 83% of days are dry.\n",
    "\n",
    "How do we operate the above to solve for $\\mathbf{s}$ in Python? There are two \"methods\". We can either use\n",
    "\n",
    "- Method 1: solve a system of linear equations with `sympy` to get $\\mathbf{s}$ or\n",
    "- Method 2: obtain $\\mathbf{s}$ via eigen decomposition.\n",
    "\n",
    "\n",
    "### Method 1: You Try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: \n",
    "Alternatively use eigen decomposition to solve for $\\mathbb{s}$. \n",
    "\n",
    "#### If your linear algebra is rusty\n",
    "To follow Method 2 you need to know a bit more about [eigen values, eigen vectors and eigen spaces](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors).\n",
    "\n",
    "Learn from Khan academy more slowly:\n",
    "-[https://www.khanacademy.org/math/linear-algebra/alternate-bases/eigen-everything/v/linear-algebra-introduction-to-eigenvalues-and-eigenvectors](https://www.khanacademy.org/math/linear-algebra/alternate-bases/eigen-everything/v/linear-algebra-introduction-to-eigenvalues-and-eigenvectors)\n",
    "\n",
    "Also, ensure you really understand the visual interactive exploration of low-dimensional eigen values and eigen vectors here:\n",
    "\n",
    "-[https://setosa.io/ev/eigenvectors-and-eigenvalues/](https://setosa.io/ev/eigenvectors-and-eigenvalues/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using numpy linalg to compute the eigenvalues and eigenvectors. It returns a tuple, the first is the array of the eigenvalues and the second is a matrix of eigenvectors. From the above, we see that the one we are after is the eigenvector corresponding to the eigenvalue $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1. , 0.4]),\n",
       " matrix([[ 0.98058068, -0.70710678],\n",
       "         [ 0.19611614,  0.70710678]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals,evecs = np.linalg.eig(P.T)\n",
    "evals,evecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors are columns of the `evecs` matrix, and it is the first we are interested in. This will have norm $1$, but we need to make sure that the sum is $1$, so that it is a probability mass function. See"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83333333],\n",
       "       [0.16666667]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_evec = evecs[:,0]\n",
    "np.array(first_evec) / np.sum(first_evec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "chcRainfallData = np.genfromtxt('data/rainfallInChristchurch.csv', delimiter=\",\")\n",
    "## Yeah, this is a much easier way to read a csv file into numpy array! \n",
    "## But this data was preformatted with no errors during type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25044"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chcRainfallData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19430802.,        0.],\n",
       "       [19430803.,        0.],\n",
       "       [19430804.,        0.],\n",
       "       [19430805.,        0.],\n",
       "       [19430806.,        0.],\n",
       "       [19430807.,        0.],\n",
       "       [19430808.,        0.],\n",
       "       [19430809.,        0.],\n",
       "       [19430810.,        0.],\n",
       "       [19430811.,        0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chcRainfallData[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20120506.,        0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chcRainfallData[-1] # the data goes from 1943 August 02 to 2012 May 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9e3413863b4879bcb32bb3c04dada2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='start_date', max=24944), IntSlider(value=10, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "@interact\n",
    "def chch_precipitation(start_date = IntSlider(0,0,len(chcRainfallData)-100,1), end_date = IntSlider(0,10,len(chcRainfallData)-1,1)):\n",
    "    sel_data = chcRainfallData[start_date:end_date]\n",
    "    sel_daysdata = np.array([[i,sel_data[i][1]] for i in range(len(sel_data))])\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.scatter(sel_daysdata[:,0],sel_daysdata[:,1])\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_daysdata = (chcRainfallData[:,1] > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_daysdata[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3439945695575787"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_daysdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive cell to allow you to select some specific data and turn it into the list of 0 or 1 tuples (this list will then be available in `sel_daysdata` in later cells in the worksheet).\n",
    "\n",
    "#### Daily Precipitation at Christchurch, fed from NIWA data (NZ's equivalent of US's NOAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def chch_wetdry(start_date = IntSlider(0,0,len(chcRainfallData)-100,1), end_date = IntSlider(0,10,len(chcRainfallData)-1,1)):\n",
    "    #global all_daysdata  # made it a global so it is easy to choose data\n",
    "    sel_data = all_daysdata[start_date:end_date]\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.scatter(range(end_date-start_date),sel_data)\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('Dry/Wet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood estimation of the unknown transition probabilities \n",
    "#### for the Dry-Wet Markov chain model of Christchurch weather\n",
    "\n",
    "In the example we have been working with earlier, the transition probabilities were given by the matrix $$\\mathbf{P}=\\begin{bmatrix} 0.9 & 0.1\\\\0.5&0.5\\end{bmatrix}$$ and we simply used the given $\\mathbf{P}$ to understand the properties and utilities of the probability model for a possibly dependent sequence of $\\{0,1\\}$-valued random variables encoding the $\\{\\text{Dry},\\text{Wet}\\}$ days, respectively.\n",
    "\n",
    "What we want to do now is use the data from Christchurch's Aeroclub obtained from NIWA to estimate Christchurch's unknown transition probability matrix $$\\mathbf{P}= \\begin{bmatrix} p_{0,0} & p_{0,1}\\\\ p_{1,0} & p_{1,1} \\end{bmatrix}.$$ \n",
    "\n",
    "Minimizing the empirical log loss we get\n",
    "\n",
    "$$\\widehat{p}_{0,0} = \\frac{n_{0,0}}{n_{0,0}+n_{0,1}} \\quad \\text{and} \\quad \\widehat{p}_{1,1} = \\frac{n_{1,1}}{n_{1,0}+n_{1,1}}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import makeFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_data = np.stack([all_daysdata[:-1],all_daysdata[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions_data[:,200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0, 12334],\n",
       "       [    0,     1,  4094],\n",
       "       [    1,     0,  4094],\n",
       "       [    1,     1,  4521]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_counts = makeFreq(transitions_data)\n",
    "transition_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12334, 4094, 4094, 4521)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_00 = transition_counts[0,-1]\n",
    "n_01 = transition_counts[1,-1]\n",
    "n_10 = transition_counts[2,-1]\n",
    "n_11 = transition_counts[3,-1]\n",
    "n_00, n_01, n_10, n_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function to make a transition counts matrix from any list of 0/1 tuples passed in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function to turn transitions counts into a matrix of values for:\n",
    "\n",
    "$$\\widehat{\\mathbf{P}}=\\begin{bmatrix} \\hat{p}_{0,0} & \\hat{p}_{0,1}\\\\ \\hat{p}_{1,0} & \\hat{p}_{1,1}\\end{bmatrix}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateMatrix(n_00,n_01,n_10,n_11):\n",
    "    p00 = n_00/(n_00+n_01)\n",
    "    p11 = n_11/(n_11+n_10)\n",
    "    p10 = 1-p11\n",
    "    p01 = 1-p00\n",
    "    return np.matrix([[p00,p01],[p10,p11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at this for all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.75079133, 0.24920867],\n",
       "        [0.47521764, 0.52478236]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimateMatrix(n_00,n_01,n_10,n_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals,evecs = np.linalg.eig(estimateMatrix(n_00,n_01,n_10,n_11).T)\n",
    "# During the lecture I forgot to transpose the transition matrix above\n",
    "# which I should have due to the computation I did on the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.27557369]),\n",
       " matrix([[ 0.88561302, -0.70710678],\n",
       "         [ 0.46442392,  0.70710678]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals,evecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.65599169],\n",
       "        [0.34400831]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evecs[:,0]/np.sum(evecs[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YouTry\n",
    "\n",
    "Consider the Markov chain describing the mode of transport used by a lazy professor. He has only two modes of transport, namely Walk or Drive. Label Walk by $0$ and Drive by $1$. If he walks today then he will definitely drive tomorrow. But, if he drives today then he flips a fair coin to decide whether he will Walk or Drive tomorrow. His decision to get to work is the same on each day. In the cells below try to:\n",
    "\n",
    "- Find the flow diagram\n",
    "- Find and assign the transition probability matrix for this Markov chain\n",
    "- Find the probability that he will drive on the $n$-th day given he will walk today (day $0$)\n",
    "- What is the steady state probability vector for this chain?\n",
    "\n",
    "**Also do by hand!**\n",
    "\n",
    "<br\\> <br \\> <br\\> <br \\>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
